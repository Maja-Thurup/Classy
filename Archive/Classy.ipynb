{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Noah X. Deutsch / Flatiron School / Data Science Program / Capstone Project\n",
    "\n",
    "# Classy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p>    <b>About: </b>\n",
    "Classy is a python package that lets anybody create their own basic machine learning classifier from any dataset in under 10 lines of code. </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from os import walk\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import pandas_profiling\n",
    "from pandas_profiling import ProfileReport\n",
    "from tabulate import tabulate\n",
    "from IPython.display import display, HTML\n",
    "import statistics \n",
    "from statistics import mode\n",
    "from statistics import StatisticsError\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True' #This fixes a bug in XGB that crashes the Kernel\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "\n",
    "class Classy:\n",
    "    def __init__(self):\n",
    "        self.chosen_file = None\n",
    "        self.og_df = None\n",
    "        self.y_name = None\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "        self.model_comparison = {}\n",
    "        self.scrubbed = False\n",
    "        self.best_model = None\n",
    "        self.scaler = None\n",
    "        print('\\n––––––––––––––––––––––––––––––––––––')\n",
    "        print(self.color.BOLD+'Welcome to CLASSY!'+self.color.END)\n",
    "        print('––––––––––––––––––––––––––––––––––––\\n')\n",
    "        print('Call the ' + self.color.BLUE +'about()'+self.color.END + ' function to learn more about how CLASSY works.')\n",
    "        print('OR Call the ' + self.color.BLUE +'obtain()'+self.color.END + ' function to select your data and get started.\\n')\n",
    "    \n",
    "    def about(self):\n",
    "        print('------------------------------------')\n",
    "        print('About ClassifyBot')\n",
    "        print('------------------------------------')\n",
    "        \n",
    "        print('\\nCLASSY allows anybody to setup a basic ML classification workflow in less than 10 lines of code, with any dataset, and minimal prior experience required.')\n",
    "        print('CLASSY makes both binary and multi-class classification simple. The full source code is available and can be customized to suit your needs.')\n",
    "        print('CLASSY has 5 primary functions (recommended to call in sequential order):')\n",
    "        print('\\t'+self.color.BLUE+'–obtain()'+self.color.END)\n",
    "        print('\\t'+self.color.BLUE+'–explore()'+self.color.END)\n",
    "        print('\\t'+self.color.BLUE+'–scrub()'+self.color.END)\n",
    "        print('\\t'+self.color.BLUE+'–model()'+self.color.END)\n",
    "        print('\\t'+self.color.BLUE+'–interpret()'+self.color.END)\n",
    "        print('\\t'+self.color.BLUE+'–predict()'+self.color.END)\n",
    "        print('\\nCall the ' + self.color.BLUE +'obtain()'+self.color.END +' function to select your data and get started.\\n')\n",
    "    \n",
    "    class color:\n",
    "        PURPLE = '\\033[95m'\n",
    "        CYAN = '\\033[96m'\n",
    "        DARKCYAN = '\\033[36m'\n",
    "        BLUE = '\\033[94m'\n",
    "        GREEN = '\\033[92m'\n",
    "        YELLOW = '\\033[93m'\n",
    "        RED = '\\033[91m'\n",
    "        BOLD = '\\033[1m'\n",
    "        UNDERLINE = '\\033[4m'\n",
    "        END = '\\033[0m'\n",
    "    \n",
    "    #Reusable confusion matrix function\n",
    "    def conf_mat(self,name,val_preds,y_test):\n",
    "\n",
    "        cnf_matrix = confusion_matrix(val_preds, y_test)\n",
    "        plt.imshow(cnf_matrix,  cmap=plt.cm.Blues) #Create the basic matrix.\n",
    "\n",
    "        #Add title and Axis Labels\n",
    "        plt.title('Confusion Matrix for ' + str(name))\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "\n",
    "        #Add appropriate Axis Scales\n",
    "        \n",
    "        class_names = np.unique(y_test) #Get class labels to add to matrix\n",
    "        \n",
    "        tick_marks = np.arange(len(class_names))\n",
    "        plt.xticks(tick_marks, class_names, rotation=45)\n",
    "        plt.yticks(tick_marks, class_names)\n",
    "\n",
    "\n",
    "        #Add Labels to Each Cell\n",
    "        thresh = cnf_matrix.max() / 2. #Used for text coloring below\n",
    "        #Here we iterate through the confusion matrix and append labels to our visualization.\n",
    "        for i, j in itertools.product(range(cnf_matrix.shape[0]), range(cnf_matrix.shape[1])):\n",
    "                plt.text(j, i, cnf_matrix[i, j],\n",
    "                         horizontalalignment=\"center\",\n",
    "                         color=\"white\" if cnf_matrix[i, j] > thresh else \"black\")\n",
    "\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "    #Generic Error Message Function\n",
    "    def error(self):\n",
    "        print(self.color.RED +'\\nWhoops, something went wrong. Please try launching Classify-Bot again.'+ self.color.END)\n",
    "        \n",
    "    #Obtain Data Function\n",
    "    def obtain(self):\n",
    "        print('\\n------------------------------------')\n",
    "        print('Obtaining Your Data')\n",
    "        print('------------------------------------')\n",
    "        \n",
    "        self.scrubbed = False\n",
    "        \n",
    "        print(self.color.BOLD+\"\\nSelect The File You Want to Work With\\n\"+self.color.END)\n",
    "        mypath = os.path.abspath(os.getcwd())\n",
    "        files = []\n",
    "        for (dirpath, dirnames, filenames) in walk(mypath):\n",
    "            files.extend(filenames)\n",
    "            break\n",
    "        csvs = []\n",
    "        for file in files:\n",
    "            if '.csv' in file:\n",
    "                csvs.append(file)\n",
    "        print('I found ' + self.color.BLUE + self.color.BOLD + str(len(csvs)) + self.color.END +' CSV files in your directory that we can get started with.')\n",
    "        if len(csvs) > 0:\n",
    "            print('Which data set do you want to work with?\\n')\n",
    "            i = 1\n",
    "            for csv in csvs:\n",
    "                print(i,'-',csv)\n",
    "                i+=1\n",
    "            print(self.color.GREEN + '\\nEnter the number of the file'+ self.color.END)\n",
    "\n",
    "            file_choice = input()\n",
    "\n",
    "            if file_choice.isnumeric() and (int(file_choice) in range(1,len(csvs)+1)):\n",
    "                self.chosen_file = csvs[int(file_choice)-1]\n",
    "                self.og_df = pd.read_csv(self.chosen_file)\n",
    "                \n",
    "                #Identify Target –––––––––––––––––––––––––\n",
    "                print(self.color.BOLD+\"\\nIdentify Target\\n\"+self.color.END)    \n",
    "                i = 1 #counter\n",
    "                col_array = []\n",
    "                for col in self.og_df.columns: \n",
    "                    print(self.color.BOLD,str(i) +':',col,self.color.END, '(DType:',self.og_df.dtypes[col],  '– NUnique:', self.og_df[col].nunique(),')')\n",
    "                    i+=1\n",
    "                    col_array.append(col)\n",
    "                target = input(\"Which of these columns represents the category you are trying to predict?\" + self.color.GREEN + ' Type in the associated column number below.'+ self.color.END+'\\n')        \n",
    "                if target.isnumeric() and (int(target) in range(1,len(self.og_df.columns)+1)):\n",
    "                    target = int(target)\n",
    "                    y_col = col_array[target-1]\n",
    "\n",
    "                    self.y_name = y_col\n",
    "\n",
    "                    print('\\nTarget Variable Selected =',self.color.BLUE+str(y_col)+self.color.END)\n",
    "                else:\n",
    "                    return None \n",
    "                \n",
    "                \n",
    "                self.y = self.og_df[self.y_name]\n",
    "                self.x = self.og_df.drop(self.y_name,axis=1)\n",
    "                \n",
    "                #Instructions\n",
    "                print(self.color.BOLD+\"\\nNext Steps\\n\"+self.color.END)\n",
    "                print('\\n'+'Great. All set to get started with ' + self.chosen_file + '. Call the' + self.color.BLUE + ' scrub()' + self.color.END + ' function to continue.')\n",
    "                print('\\nYou can also explore the unscrubbed dataset by calling the ' + self.color.BLUE + 'explore()' + self.color.END + ' function.')\n",
    "                print('\\nLastly, If your file is already scrubbed and model ready, you can proceed straight to the ' + self.color.BLUE + ' model()' + self.color.END + ' function.')\n",
    "            else:\n",
    "                self.error()\n",
    "                return(None)\n",
    "        else:\n",
    "            print('Please upload a CSV File to Begin')\n",
    "            return(None)\n",
    "        \n",
    " \n",
    "    #Scrubbing Function\n",
    "    def scrub(self):   \n",
    "        print('\\n------------------------------------')\n",
    "        print('Scrubbing Your Data')\n",
    "        print('------------------------------------')\n",
    "        df = pd.read_csv(self.chosen_file)\n",
    "        self.x = pd.read_csv(self.chosen_file)\n",
    "        col = df.shape[1]\n",
    "        row = df.shape[0]\n",
    "        print('\\n' + self.chosen_file + ' has ' + str(col) + ' columns and ' + str(row) + ' rows\\n')\n",
    "        \n",
    "        #Take a smaller sample –––––––––––––––––––––––––\n",
    "        print(self.color.BOLD+\"Step 0. Take a sample (optional)\\n\"+self.color.END)\n",
    "        if len(df) > 100000:\n",
    "            print(\"Looks like your working with a LOT of data! That's great, but...\")\n",
    "            print(\"Sometimes that can make our models take a long time to run on a regular computer.\")\n",
    "            choice = input(\"Would you like to take a smaller sample of the data to speed things up?\" + self.color.GREEN + ' Type (y/n) below'+ self.color.END+'\\n')\n",
    "            if choice == 'y':\n",
    "                amount = input(\"What sized sample? (I recommend starting with ~50K rows)\" + self.color.GREEN + ' Type a number below.'+ self.color.END+'\\n')\n",
    "                if amount.isnumeric():\n",
    "                    amount = int(amount)\n",
    "                    self.x = self.x.sample(n=amount,random_state=0)\n",
    "                    df = df.sample(n=amount,random_state=0)\n",
    "                else:\n",
    "                    self.error()\n",
    "                    return None\n",
    "            elif choice != 'n':\n",
    "                self.error()\n",
    "                return None\n",
    "        else:\n",
    "            print(\"Skipping this step (since you're dataset isn't overwhelmingly large)\")\n",
    "        \n",
    "        print(self.color.BOLD+\"Step 1. Remove any target values (optional)\\n\"+self.color.END)\n",
    "        #FUNCTION FOR REMOVING SPECIFIC TARGET VALUES FROM THE CLASSIFIER.\n",
    "        print('\\nYour target variable has '+ self.color.BLUE + str(self.x[self.y_name].nunique()) + self.color.END + ' unique values:')\n",
    "        print('Value counts in ' + self.color.RED + 'red' + self.color.END + ' represent less than 5% of total data (consider removing).')\n",
    "        \n",
    "        val_array = []\n",
    "        \n",
    "        for i in range(len(self.x[self.y_name].unique())):\n",
    "            if int(list(self.x[self.y_name].value_counts(dropna=False))[i]) < (.05*len(self.x[self.y_name])):  \n",
    "                print(self.color.BOLD + str(i+1) + ': ' + str(list(self.x[self.y_name].value_counts(dropna=False).index)[i]) + self.color.END, self.color.RED, str(list(self.x[self.y_name].value_counts(dropna=False))[i]) + self.color.END)\n",
    "            else: \n",
    "                print(self.color.BOLD + str(i+1) + ': ' + str(list(self.x[self.y_name].value_counts(dropna=False).index)[i]) + self.color.END, self.x[self.y_name].value_counts(dropna=False)[i])\n",
    "            val_array.append(self.x[self.y_name].unique()[i])\n",
    "            \n",
    "        print(\"Would you like to remove of any of these values (and the associated rows)?\")\n",
    "        yorno = input(\"Don't worry about NAN values for now... we'll deal with that later\" + self.color.GREEN + ' Type (y/n) below'+ self.color.END+'\\n')\n",
    "        \n",
    "        if yorno == 'y':\n",
    "            val_to_remove = input(self.color.GREEN + 'Please type in the number of each target value you want to remove, sepparating each number by a space.'+ self.color.END+'\\n')\n",
    "            val_to_remove = val_to_remove.split()\n",
    "            val_to_remove = list(map(int, val_to_remove))\n",
    "            \n",
    "            for val in val_to_remove:\n",
    "                print(val)\n",
    "                remove = val_array[val-1]\n",
    "                self.x[self.y_name] = self.x[self.y_name][self.x[self.y_name] != remove]\n",
    "                \n",
    "        \n",
    "        elif yorno != 'n':\n",
    "            self.error()\n",
    "            return None\n",
    "        \n",
    "        print(self.x[self.y_name].value_counts(dropna=False))\n",
    "\n",
    "        \n",
    "        #Removing Columns –––––––––––––––––––––––––\n",
    "        print(self.color.BOLD+\"\\nStep 2. Remove Columns (optional)\\n\"+self.color.END)        \n",
    "        \n",
    "        i = 1 #counter\n",
    "        col_array = []\n",
    "        for col in self.x.columns: \n",
    "            print(str(i) +':',col)\n",
    "            i+=1\n",
    "            col_array.append(col)\n",
    "        \n",
    "        yorno = input('\\nWould you like to remove any of the columns?'+ self.color.GREEN + ' Type (y/n) below'+ self.color.END+'\\n')\n",
    "        if yorno == 'y':\n",
    "            col_to_remove = input(self.color.GREEN + 'Please type in the number of each column you want to remove, sepparating each number by a space.'+ self.color.END+'\\n')\n",
    "            col_to_remove = col_to_remove.split()\n",
    "            col_to_remove = list(map(int, col_to_remove))\n",
    "\n",
    "            for col in col_to_remove:\n",
    "                remove = col_array[col-1]\n",
    "                self.x = self.x.drop(remove,axis=1)\n",
    "\n",
    "            print(str(len(col_to_remove)) + ' columns were successfully removed.')\n",
    "        elif yorno != 'n':\n",
    "            self.error()\n",
    "            return None\n",
    "        \n",
    "\n",
    "        #Fixing Any DataTypes –––––––––––––––––––––––––\n",
    "        print(self.color.BOLD+\"\\nStep 3. Fixing Column Data Types (optional) \\n\"+self.color.END)        \n",
    "        \n",
    "        i = 1 #counter\n",
    "        col_array = []\n",
    "        for col in self.x.columns: \n",
    "            print(str(i) +':',col,'– DType:',self.x.dtypes[col],'– Examples (' + str(self.x[col].iloc[1]) +', ' + str(self.x[col].iloc[2]) + ', ' + str(self.x[col].iloc[3]) + ')')\n",
    "            i+=1\n",
    "            col_array.append(col)\n",
    "        \n",
    "        yorno = input('\\nDo any of these column datatypes look incorrect?'+ self.color.GREEN + ' Type (y/n) below'+ self.color.END+'\\n')\n",
    "        if yorno == 'y':\n",
    "            col_to_fix = input(self.color.GREEN + 'Please type in the number of each column you want to switch the datatype for, sepparating each number by a space.'+ self.color.END+'\\n')\n",
    "            col_to_fix = col_to_fix.split()\n",
    "            col_to_fix = list(map(int, col_to_fix))\n",
    "\n",
    "            for col in col_to_fix:\n",
    "                fix = col_array[col-1]\n",
    "                \n",
    "                if(self.x[fix].dtype == np.float64 or self.x[fix].dtype == np.int64):\n",
    "                    self.x[fix] = self.x[fix].astype(str)\n",
    "                \n",
    "                else: \n",
    "                    self.x[fix] = pd.to_numeric(self.x[fix], errors='coerce')\n",
    "                    \n",
    "            print(str(len(col_to_fix)) + ' column data types were successfully changed.')\n",
    "        elif yorno != 'n':\n",
    "            self.error()\n",
    "            return None\n",
    "        \n",
    "        \n",
    "        #Deal with Missing Data –––––––––––––––––––––––––\n",
    "        print(self.color.BOLD+\"\\nStep 4. Dealing with Any Missing Data\\n\"+self.color.END)   \n",
    "        \n",
    "        if self.x.isnull().sum().sum() > 0:\n",
    "            print('The following columns have missing data we have to deal with before modelling.')\n",
    "            print('For each, you can choose how to handle the missing data.\\n')\n",
    "            \n",
    "            i=1\n",
    "            for col in self.x.columns: \n",
    "                if self.x[col].isna().sum() > 0:\n",
    "                    print(str(i) +':',col,'– Missing Data Count:',self.x[col].isna().sum(),'/ '+str(len(self.x[col])))\n",
    "                    #Data removal function here\n",
    "                    print('For this column, would you like to...')\n",
    "                    print('\\t1. REMOVE the missing rows from the data set. ')\n",
    "                    print('\\t2. REPLACE this data with the median value for numerical data or most common for categorical data)')\n",
    "                    print('\\t3. KEEP the data as is (for categorical data only)')\n",
    "                    choice = input(self.color.GREEN + 'Type in the assocated number to make your choice:'+ self.color.END+'\\n')\n",
    "                    if choice == '1':\n",
    "                        print('Missing data was removed.')\n",
    "                        self.x = self.x[self.x[col].notna()]\n",
    "                    elif choice == '2':\n",
    "                        print('Missing data was replaced.')\n",
    "                        if(self.x[col].dtype == np.float64 or self.x[col].dtype == np.int64):\n",
    "                            self.x[col].fillna(self.x[col].median(),inplace=True)\n",
    "                        else:\n",
    "                            self.x[col].fillna(self.x[col].mode(),inplace=True)\n",
    "                    elif choice == '3':\n",
    "                        print('Missing data was kept.')\n",
    "                        self.x[col].fillna('NaN')\n",
    "                    else:\n",
    "                        self.error()\n",
    "                        return None\n",
    "                    print('')\n",
    "                i+=1\n",
    "                \n",
    "                     \n",
    "        else:\n",
    "            print('No missing data found... Moving on!')\n",
    "        \n",
    "        \n",
    "        self.y = self.x[self.y_name]\n",
    "        self.x = self.x.drop(self.y_name,axis=1)\n",
    "        self.scrubbed = True\n",
    "        \n",
    "        print('\\nScrub complete! You can now access your scrubbed X and Y files at OBJECT.x and OBJECT.y respectively.')\n",
    "        print('Next, call the ' + self.color.BLUE + 'explore() ' + self.color.END +'function to select your data or you can skip straight to the ' + self.color.BLUE + 'model()' + self.color.END + 'function.')\n",
    "        \n",
    "        \n",
    "    #Explore Function\n",
    "    def explore(self):   \n",
    "        print('\\n------------------------------------')\n",
    "        print('Exploring Your Data')\n",
    "        print('------------------------------------')\n",
    "        print(self.color.UNDERLINE+'Please be patient... this may take a minute if you have a lot of data.'+self.color.END)\n",
    "\n",
    "        choice = input(\"Would you like to do a simple explore (.head, .info, .describe) or an advanced explore (using pandas profiling)\" + self.color.GREEN + ' Enter 1 for simple, or 2 for advanced.'+ self.color.END+'\\n')\n",
    "        if choice == '1':\n",
    "            if self.scrubbed == True:\n",
    "                x_eda = self.x\n",
    "                x_eda['Y'] = self.y\n",
    "\n",
    "\n",
    "\n",
    "                choice = input(\"\\nWould you like to explore the original dataset, or the scrubbed dataset?\" + self.color.GREEN + ' Enter 1 for original, or 2 for scrubbed.'+ self.color.END+'\\n')\n",
    "                \n",
    "                if choice == '1':\n",
    "                    print( '\\n' + self.color.BLUE + self.color.BOLD + 'Basic Info' + self.color.END)\n",
    "                    info = self.og_df.info()\n",
    "\n",
    "                    print( '\\n' + self.color.BLUE + self.color.BOLD + 'First 5 Rows' + self.color.END)\n",
    "                    head = self.og_df.head()\n",
    "                    display(HTML(head.to_html()))\n",
    "\n",
    "\n",
    "                    print( '\\n' + self.color.BLUE + self.color.BOLD + 'Descriptive Statistics' + self.color.END)\n",
    "                    describe = self.og_df.describe()\n",
    "                    display(HTML(describe.to_html()))                \n",
    "               \n",
    "                elif choice == '2':\n",
    "                    print( '\\n' + self.color.BLUE + self.color.BOLD + 'Basic Info' + self.color.END)\n",
    "                    info = x_eda.info()\n",
    "\n",
    "                    print( '\\n' + self.color.BLUE + self.color.BOLD + 'First 5 Rows' + self.color.END)\n",
    "                    head = x_eda.head()\n",
    "                    display(HTML(head.to_html()))\n",
    "\n",
    "\n",
    "                    print( '\\n' + self.color.BLUE + self.color.BOLD + 'Descriptive Statistics' + self.color.END)\n",
    "                    describe = x_eda.describe()\n",
    "                    display(HTML(describe.to_html()))\n",
    "                \n",
    "                else:\n",
    "                    self.error()\n",
    "                    return None\n",
    "\n",
    "            else:\n",
    "                print('\\nExploring original (unscrubbed) dataset. You can call .scrub() on the object to explore the scrubbed dataset later.')\n",
    "                \n",
    "                print( '\\n' + self.color.BLUE + self.color.BOLD + 'Basic Info' + self.color.END)\n",
    "                info = self.og_df.info()\n",
    "                               \n",
    "                print( '\\n' + self.color.BLUE + self.color.BOLD + 'First 5 Rows' + self.color.END)\n",
    "                head = self.og_df.head()\n",
    "                display(HTML(head.to_html()))\n",
    "                \n",
    "\n",
    "                print( '\\n' + self.color.BLUE + self.color.BOLD + 'Descriptive Statistics' + self.color.END)\n",
    "                describe = self.og_df.describe()\n",
    "                display(HTML(describe.to_html()))\n",
    "                #print(tabulate(self.og_df, headers='keys', tablefmt='psql'))\n",
    "        \n",
    "            \n",
    "        elif choice == '2':\n",
    "          \n",
    "            if self.scrubbed == True:\n",
    "                x_eda = self.x\n",
    "                x_eda['Y'] = self.y\n",
    "\n",
    "\n",
    "\n",
    "                choice = input(\"Would you like to explore the original dataset, or the scrubbed dataset?\" + self.color.GREEN + ' Enter 1 for original, or 2 for scrubbed.'+ self.color.END+'\\n')\n",
    "                if choice == '1':\n",
    "                    profile = self.og_df.profile_report()\n",
    "                elif choice == '2':\n",
    "                    profile = x_eda.profile_report() \n",
    "                else:\n",
    "                    self.error()\n",
    "                    return None\n",
    "\n",
    "            else:\n",
    "                print('Exploring original (unscrubbed) dataset. You can call .scrub() on the object to explore the scrubbed dataset later.')\n",
    "\n",
    "\n",
    "                profile = self.og_df.profile_report()\n",
    "\n",
    "                #profile = ProfileReport(self.og_df, \n",
    "                 #           title='Pandas Profiling Report', \n",
    "                  #          html={'style':{'full_width':True}}) \n",
    "            profile.to_notebook_iframe()\n",
    "        else:\n",
    "            self.error()\n",
    "            return None            \n",
    "        \n",
    "    #Model Data Function\n",
    "    def model(self):\n",
    "        print('\\n------------------------------------')\n",
    "        print('Modeling Your Data')\n",
    "        print('------------------------------------')\n",
    "        \n",
    "        #Get Dummies\n",
    "        print(self.color.BOLD + '\\nGetting dummy variables...' + self.color.END)\n",
    "        x_dummies = pd.get_dummies(self.x)\n",
    "        print('Pre-Dummy Shape:', self.x.shape)\n",
    "        print('Post-Dummy Shape:', x_dummies.shape)\n",
    "                \n",
    "\n",
    "        #Data Scaling\n",
    "        print(self.color.BOLD + '\\nScaling your data...' + self.color.END)\n",
    "            \n",
    "        print(\"Would you like to normalize (Min-Max scaler) or Standardize (standard scaler) the data?\")\n",
    "        choice = input(self.color.GREEN + 'Enter 1 for MinMax (Recommended), 2 for Standard Scaler, or 3 to skip.'+ self.color.END+'\\n')\n",
    "        if choice == '1':\n",
    "            scaler = MinMaxScaler()\n",
    "            print('MinMax Scaler Selected')\n",
    "            self.scaler = MinMaxScaler()\n",
    "        elif choice == '2':\n",
    "            scaler = StandardScaler() \n",
    "            print('Standard Scaler Selected.')\n",
    "            self.scaler = StandardScaler()\n",
    "        elif choice == '3':\n",
    "            print('Skipping data scaling.')\n",
    "            self.scaler = None\n",
    "        else:\n",
    "            self.error()\n",
    "            return None   \n",
    "        \n",
    "        if choice == '1' or choice == '2':\n",
    "            x_final = self.scaler.fit_transform(x_dummies)\n",
    "\n",
    "            print('Scaling complete.')\n",
    "            print( '\\nHere are the ' + self.color.BLUE + self.color.BOLD + 'first 3 rows' + self.color.END + ' to confirm the change was successfully made.')\n",
    "            head = pd.DataFrame(x_final).head(3)\n",
    "            display(HTML(head.to_html()))    \n",
    "        else:\n",
    "            x_final = x_dummies\n",
    "        \n",
    "        #Train Test Split\n",
    "        print(self.color.BOLD + '\\nSplitting up your train and test data...' + self.color.END)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x_final, self.y, stratify=self.y,random_state=0)\n",
    "   \n",
    "        \n",
    "        #Model Choices\n",
    "        print(self.color.BOLD + '\\nChosing Which Models to Use...' + self.color.END)\n",
    "        print(self.color.RED + '\\nHeads up: ' + self.color.END + 'Selecting multiple models may result in extreme wait times.')\n",
    "        print('You can always start with 1-2 models and add more later.')\n",
    "        print('All models previously run can be compared by calling ' + self.color.BLUE + '.interpret()'+ self.color.END + ' later.\\n')\n",
    "        \n",
    "        model_array = [['Decision Tree',False],\n",
    "                       ['Random Forrest',False],\n",
    "                       ['AdaBoost',False],\n",
    "                       ['XGBoost',False],\n",
    "                       ['Linear Support Vector',False],\n",
    "                       ['Neural Network',False]]\n",
    "        \n",
    "        for i in range(len(model_array)):\n",
    "            print(i+1,model_array[i][0])\n",
    "        \n",
    "        model_choice = input(self.color.GREEN + '\\nPlease type in the corrosponding number of each model you want to run, sepparating each number by a space.'+ self.color.END+'\\n')\n",
    "        model_choice = model_choice.split()\n",
    "        model_choice = list(map(int, model_choice))\n",
    "        \n",
    "        for model in model_choice:\n",
    "            model_array[model-1][1] = True\n",
    "            print(model_array[model-1])\n",
    "        \n",
    "        \n",
    "        print(self.color.BOLD + '\\nTraining Baseline Models' + self.color.END)\n",
    "        \n",
    "        #Decision Tree\n",
    "        if model_array[0][1] == True:\n",
    "            print('\\nDecision Tree Launching...')\n",
    "\n",
    "            now = datetime.now()\n",
    "            current_time = now.strftime(\"%D, %H:%M:%S\")            \n",
    "\n",
    "            dt_clf = DecisionTreeClassifier(random_state=0)\n",
    "            dt_clf.fit(X_train, y_train)\n",
    "            training_preds = dt_clf.predict(X_train)\n",
    "            val_preds = dt_clf.predict(X_test)\n",
    "            training_accuracy = accuracy_score(y_train, training_preds)\n",
    "            val_accuracy = accuracy_score(y_test, val_preds)\n",
    "\n",
    "            print(\"Training Accuracy: {:.4}%\".format(training_accuracy * 100))\n",
    "            print(\"Validation accuracy: {:.4}%\".format(val_accuracy * 100))\n",
    "            \n",
    "            self.model_comparison['Decision Tree'] = {'Model':dt_clf,'Train Accuracy':round(training_accuracy,4),'Test Accuracy':round(val_accuracy,4),'Time Run':current_time}\n",
    "\n",
    "        #Random Forrest\n",
    "        if model_array[1][1] == True:\n",
    "            print('\\nRandom Forrest Launching...')\n",
    " \n",
    "            now = datetime.now()\n",
    "            current_time = now.strftime(\"%D, %H:%M:%S\")            \n",
    "            \n",
    "            rf_clf = RandomForestClassifier(random_state=0)\n",
    "            rf_clf.fit(X_train, y_train)\n",
    "            training_preds = rf_clf.predict(X_train)\n",
    "            val_preds = rf_clf.predict(X_test)\n",
    "            training_accuracy = accuracy_score(y_train, training_preds)\n",
    "            val_accuracy = accuracy_score(y_test, val_preds)\n",
    "\n",
    "            print(\"Training Accuracy: {:.4}%\".format(training_accuracy * 100))\n",
    "            print(\"Validation accuracy: {:.4}%\".format(val_accuracy * 100))\n",
    "            \n",
    "            self.model_comparison['Random Forrest'] = {'Model':rf_clf,'Train Accuracy':round(training_accuracy,4),'Test Accuracy':round(val_accuracy,4),'Time Run':current_time}\n",
    "            \n",
    "        #Adaboost\n",
    "        if model_array[2][1] == True:\n",
    "            print('\\nAdaboost Launching...')\n",
    "            \n",
    "            now = datetime.now()\n",
    "            current_time = now.strftime(\"%D, %H:%M:%S\")            \n",
    "\n",
    "            ab_clf = AdaBoostClassifier(random_state=0)\n",
    "            ab_clf.fit(X_train, y_train)\n",
    "            training_preds = ab_clf.predict(X_train)\n",
    "            val_preds = ab_clf.predict(X_test)\n",
    "            training_accuracy = accuracy_score(y_train, training_preds)\n",
    "            val_accuracy = accuracy_score(y_test, val_preds)\n",
    "            \n",
    "            print(\"Training Accuracy: {:.4}%\".format(training_accuracy * 100))\n",
    "            print(\"Validation accuracy: {:.4}%\".format(val_accuracy * 100))\n",
    "                        \n",
    "            self.model_comparison['Adaboost'] = {'Model':ab_clf,'Train Accuracy':round(training_accuracy,4),'Test Accuracy':round(val_accuracy,4),'Time Run':current_time}\n",
    "\n",
    "        #XGBoost\n",
    "        if model_array[3][1] == True:\n",
    "            print('\\nXGBoost Launching...')\n",
    "\n",
    "            now = datetime.now()\n",
    "            current_time = now.strftime(\"%D, %H:%M:%S\")            \n",
    "\n",
    "            xgb_clf = xgb.XGBClassifier(random_state=0)\n",
    "            xgb_clf.fit(X_train, y_train)\n",
    "            training_preds = xgb_clf.predict(X_train)\n",
    "            val_preds = xgb_clf.predict(X_test)\n",
    "            training_accuracy = accuracy_score(y_train, training_preds)\n",
    "            val_accuracy = accuracy_score(y_test, val_preds)\n",
    "          \n",
    "            print(\"Training Accuracy: {:.4}%\".format(training_accuracy * 100))\n",
    "            print(\"Validation accuracy: {:.4}%\".format(val_accuracy * 100))\n",
    "            \n",
    "            self.model_comparison['XGBoost'] = {'Model':xgb_clf,'Train Accuracy':round(training_accuracy,4),'Test Accuracy':round(val_accuracy,4),'Time Run':current_time}\n",
    "\n",
    "        #Linear Support Vector\n",
    "        if model_array[4][1] == True:\n",
    "            print('\\nLinear Support Vector Launching...')\n",
    "            \n",
    "            now = datetime.now()\n",
    "            current_time = now.strftime(\"%D, %H:%M:%S\")            \n",
    "            \n",
    "            svc_clf = LinearSVC(random_state=0)\n",
    "            svc_clf.fit(X_train, y_train)\n",
    "            training_preds = svc_clf.predict(X_train)\n",
    "            val_preds = svc_clf.predict(X_test)\n",
    "            training_accuracy = accuracy_score(y_train, training_preds)\n",
    "            val_accuracy = accuracy_score(y_test, val_preds)\n",
    "            \n",
    "            print(\"Training Accuracy: {:.4}%\".format(training_accuracy * 100))\n",
    "            print(\"Validation accuracy: {:.4}%\".format(val_accuracy * 100))\n",
    "                  \n",
    "            self.model_comparison['Linear SVC'] = {'Model':svc_clf,'Train Accuracy':round(training_accuracy,4),'Test Accuracy':round(val_accuracy,4),'Time Run':current_time}\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        best = []\n",
    "        \n",
    "        for k, v in self.model_comparison.items():\n",
    "            if best == []:\n",
    "                best = [k, v]\n",
    "            else:\n",
    "                if best[1]['Test Accuracy'] < v['Test Accuracy']:\n",
    "                    best = [k, v]      \n",
    "        \n",
    "        print(\"\\nThe best performing model was:\",self.color.PURPLE,best[0],'– with a Test Accuracy of: ',best[1]['Test Accuracy'], self.color.END)\n",
    "        \n",
    "        print(self.color.BOLD + '\\nOptimizing Models' + self.color.END)\n",
    "        \n",
    "        \n",
    "        #Optimization ------------------------------------------------\n",
    "\n",
    "        \n",
    "        #Grid Search for Decision Tree\n",
    "        \n",
    "        if model_array[0][1] == True:\n",
    "            print('\\nOptimizing Decision Tree...')\n",
    "            param_grid = {\n",
    "                \"max_depth\": [10,50,100,500,1000,None],\n",
    "                \"criterion\": [\"gini\", \"entropy\"],\n",
    "                \"min_samples_split\": [2,3,4,5],\n",
    "                'random_state': [0]\n",
    "            }\n",
    "\n",
    "            grid_clf = GridSearchCV(dt_clf, param_grid, scoring='accuracy', cv=None, n_jobs=1)\n",
    "            grid_clf.fit(X_train, y_train)\n",
    "\n",
    "            best_parameters = grid_clf.best_params_\n",
    "\n",
    "            print(\"Grid Search found the following optimal parameters: \")\n",
    "            for param_name in sorted(best_parameters.keys()):\n",
    "                print(\"%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "            training_preds = grid_clf.predict(X_train)\n",
    "            val_preds = grid_clf.predict(X_test)\n",
    "            training_accuracy = accuracy_score(y_train, training_preds)\n",
    "            val_accuracy = accuracy_score(y_test, val_preds)\n",
    "\n",
    "            print(\"Training Accuracy: {:.4}%\".format(training_accuracy * 100))\n",
    "            print(\"Validation accuracy: {:.4}%\".format(val_accuracy * 100))\n",
    "\n",
    "            self.model_comparison['Optimized Decision Tree'] = {'Model':grid_clf,'Train Accuracy':round(training_accuracy,4),'Test Accuracy':round(val_accuracy,4),'Time Run':current_time}\n",
    "\n",
    "            #print confusion matrix\n",
    "            self.conf_mat('Optimized Decision Tree',val_preds,y_test)\n",
    "            \n",
    "        #Grid Search for Random Forrest\n",
    "        if model_array[1][1] == True:\n",
    "            print('\\nOptimizing Random Forrest...')\n",
    "            param_grid = {\n",
    "                \"n_estimators\": [10,50,100,500],\n",
    "                \"max_depth\": [10,50,100,500,1000,None],\n",
    "                'random_state': [0]\n",
    "            }\n",
    "\n",
    "            grid_clf = GridSearchCV(rf_clf, param_grid, scoring='accuracy', cv=None, n_jobs=1)\n",
    "            grid_clf.fit(X_train, y_train)\n",
    "\n",
    "            best_parameters = grid_clf.best_params_\n",
    "\n",
    "            print(\"Grid Search found the following optimal parameters: \")\n",
    "            for param_name in sorted(best_parameters.keys()):\n",
    "                print(\"%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "            training_preds = grid_clf.predict(X_train)\n",
    "            val_preds = grid_clf.predict(X_test)\n",
    "            training_accuracy = accuracy_score(y_train, training_preds)\n",
    "            val_accuracy = accuracy_score(y_test, val_preds)\n",
    "\n",
    "            print(\"Training Accuracy: {:.4}%\".format(training_accuracy * 100))\n",
    "            print(\"Validation accuracy: {:.4}%\".format(val_accuracy * 100))\n",
    "\n",
    "            self.model_comparison['Optimized Random Forrest'] = {'Model':grid_clf,'Train Accuracy':round(training_accuracy,4),'Test Accuracy':round(val_accuracy,4),'Time Run':current_time}\n",
    "\n",
    "            #print confusion matrix\n",
    "            self.conf_mat('Optimized Random Forrest',val_preds,y_test)\n",
    "\n",
    "        #Grid Search for AdaBoost\n",
    "        if model_array[2][1] == True:\n",
    "            print('\\nOptimizing AdaBoost...')\n",
    "            param_grid = {\n",
    "                'learning_rate':[.1,.5,1],\n",
    "                \"n_estimators\": [10,50,100,500,1000],\n",
    "                'random_state': [0]\n",
    "            }\n",
    "\n",
    "            grid_clf = GridSearchCV(ab_clf, param_grid, scoring='accuracy', cv=None, n_jobs=1)\n",
    "            grid_clf.fit(X_train, y_train)\n",
    "\n",
    "            best_parameters = grid_clf.best_params_\n",
    "\n",
    "            print(\"Grid Search found the following optimal parameters: \")\n",
    "            for param_name in sorted(best_parameters.keys()):\n",
    "                print(\"%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "            training_preds = grid_clf.predict(X_train)\n",
    "            val_preds = grid_clf.predict(X_test)\n",
    "            training_accuracy = accuracy_score(y_train, training_preds)\n",
    "            val_accuracy = accuracy_score(y_test, val_preds)\n",
    "\n",
    "            print(\"\")\n",
    "            print(\"Training Accuracy: {:.4}%\".format(training_accuracy * 100))\n",
    "            print(\"Validation accuracy: {:.4}%\".format(val_accuracy * 100))\n",
    "\n",
    "            self.model_comparison['Optimized AdaBoost'] = {'Model':grid_clf,'Train Accuracy':round(training_accuracy,4),'Test Accuracy':round(val_accuracy,4),'Time Run':current_time}\n",
    "            \n",
    "            #print confusion matrix\n",
    "            self.conf_mat('Optimized AdaBoost',val_preds,y_test)\n",
    "\n",
    "        #Grid Search for XGBoost\n",
    "        if model_array[3][1] == True:\n",
    "            print('\\nOptimizing XGBoost...')\n",
    "            param_grid = {\n",
    "                'eta':[.1,.3,.5,.9],\n",
    "                'max_depth':[3,6,12],\n",
    "                'lambda':[0,1],\n",
    "                'alpha':[0,1],\n",
    "                'random_state': [0]\n",
    "            }\n",
    "\n",
    "            grid_clf = GridSearchCV(xgb_clf, param_grid, scoring='accuracy', cv=None, n_jobs=1)\n",
    "            grid_clf.fit(X_train, y_train)\n",
    "\n",
    "            best_parameters = grid_clf.best_params_\n",
    "\n",
    "            print(\"Grid Search found the following optimal parameters: \")\n",
    "            for param_name in sorted(best_parameters.keys()):\n",
    "                print(\"%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "            training_preds = grid_clf.predict(X_train)\n",
    "            val_preds = grid_clf.predict(X_test)\n",
    "            training_accuracy = accuracy_score(y_train, training_preds)\n",
    "            val_accuracy = accuracy_score(y_test, val_preds)\n",
    "\n",
    "            print(\"\")\n",
    "            print(\"Training Accuracy: {:.4}%\".format(training_accuracy * 100))\n",
    "            print(\"Validation accuracy: {:.4}%\".format(val_accuracy * 100))\n",
    "\n",
    "            self.model_comparison['Optimized XGBoost'] = {'Model':grid_clf,'Train Accuracy':round(training_accuracy,4),'Test Accuracy':round(val_accuracy,4),'Time Run':current_time}\n",
    "            \n",
    "            #print confusion matrix\n",
    "            self.conf_mat('Optimized XGBoost',val_preds,y_test)\n",
    "\n",
    "        #Grid Search for Linear SVC\n",
    "        if model_array[4][1] == True:\n",
    "            print('\\nOptimizing Linear SVC...')\n",
    "            param_grid = {\n",
    "                'loss':['hinge', 'squared_hinge'],\n",
    "                'C':[1,10,100],\n",
    "                'class_weight':[None,'balanced'],\n",
    "                'max_iter':[1000,2000,3000],\n",
    "                'random_state': [0]\n",
    "            }\n",
    "\n",
    "            grid_clf = GridSearchCV(svc_clf, param_grid, scoring='accuracy', cv=None, n_jobs=1)\n",
    "            grid_clf.fit(X_train, y_train)\n",
    "\n",
    "            best_parameters = grid_clf.best_params_\n",
    "\n",
    "            print(\"Grid Search found the following optimal parameters: \")\n",
    "            for param_name in sorted(best_parameters.keys()):\n",
    "                print(\"%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "            training_preds = grid_clf.predict(X_train)\n",
    "            val_preds = grid_clf.predict(X_test)\n",
    "            training_accuracy = accuracy_score(y_train, training_preds)\n",
    "            val_accuracy = accuracy_score(y_test, val_preds)\n",
    "\n",
    "            print(\"\")\n",
    "            print(\"Training Accuracy: {:.4}%\".format(training_accuracy * 100))\n",
    "            print(\"Validation accuracy: {:.4}%\".format(val_accuracy * 100))\n",
    "\n",
    "            self.model_comparison['Optimized Linear SVC'] = {'Model':grid_clf,'Train Accuracy':round(training_accuracy,4),'Test Accuracy':round(val_accuracy,4),'Time Run':current_time}\n",
    "            \n",
    "            #print confusion matrix\n",
    "            self.conf_mat('Optimized Linear SVC',val_preds,y_test)            \n",
    "\n",
    "        best = []\n",
    "        \n",
    "        for k, v in self.model_comparison.items():\n",
    "            if best == []:\n",
    "                best = [k, v]\n",
    "            else:\n",
    "                if best[1]['Test Accuracy'] < v['Test Accuracy']:\n",
    "                    best = [k, v]     \n",
    "        \n",
    "        print(\"\\nThe best performing model was:\",self.color.PURPLE,best[0],'– with a Test Accuracy of: ',best[1]['Test Accuracy'], self.color.END)\n",
    "        \n",
    "        print('\\nModeling Complete! Next, call the ' + self.color.BLUE + '.interpret()' + self.color.END + ' function.')\n",
    "   \n",
    "        self.best_model = best\n",
    "    \n",
    "    #Interpret Model Performance Function\n",
    "    def interpret(self):\n",
    "        print('\\n------------------------------------')\n",
    "        print('Interpreting Your Results')\n",
    "        print('------------------------------------\\n')\n",
    "        \n",
    "        model_name = []\n",
    "        model_acc = []\n",
    "\n",
    "        for k, v in self.model_comparison.items():\n",
    "            model_name.append(str(k))\n",
    "            model_acc.append(v['Test Accuracy'])  \n",
    "\n",
    "        fig, ax  = plt.subplots(figsize = (12,6))\n",
    "        \n",
    "        minlim = min(list(model_acc)) - .01\n",
    "        maxlim = max(list(model_acc)) + .01\n",
    "        \n",
    "        plt.xlabel(\"Models\",fontsize = 15, fontweight = 'medium')\n",
    "        plt.ylabel(\"Test Data Accuracy\",fontsize = 15, fontweight = 'medium')\n",
    "        \n",
    "        ax.set_ylim([minlim, maxlim],auto=False)    \n",
    "        ax.bar(model_name,model_acc)\n",
    "        \n",
    "        plt.title('Model Performance Comparison',fontsize = 20, fontweight = 'semibold')\n",
    "        \n",
    "        \n",
    "        for i, v in enumerate(model_acc):\n",
    "            ax.text(i, \n",
    "                    minlim+.003, \n",
    "                    model_acc[i], \n",
    "                    fontsize=12,\n",
    "                   horizontalalignment='center',\n",
    "                   color = 'white')\n",
    "        \n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\\nThe best performing model was:\",self.color.PURPLE,self.best_model[0],'– with a Test Accuracy of: ',self.best_model[1]['Test Accuracy'], self.color.END)\n",
    "        \n",
    "    def predict(self):\n",
    "        print('\\n------------------------------------')\n",
    "        print('Making a Prediction')\n",
    "        print('------------------------------------')\n",
    "        \n",
    "        print(self.color.BOLD+'\\nPlease provide the input values to make a prediction. (MUST be correct data type)'+self.color.END)\n",
    "\n",
    "        inputs = []\n",
    "        for col in self.x.columns:\n",
    "            val = input('Value for: '+ self.color.BLUE + str(col) + self.color.END +'?' + ' (Type = ' + str(self.x[col].dtypes) + ')' + ' (Example = ' + str(self.x[col].iloc[0]) + ')' )\n",
    "            \n",
    "            if(self.x[col].dtype == np.float64):\n",
    "                val = float(val)\n",
    "            if(self.x[col].dtype == np.int64):\n",
    "                val = int(val)\n",
    "            inputs.append(val)\n",
    "\n",
    "        \n",
    "        inputs = [inputs]\n",
    "        \n",
    "        #getting dummies\n",
    "        input_dummies = pd.get_dummies(pd.DataFrame(inputs))\n",
    "        \n",
    "        #scaling inputs\n",
    "        if self.scaler != None:\n",
    "            final_inputs = self.scaler.transform(input_dummies)\n",
    "        \n",
    "        #Back to numpy\n",
    "        #final_inputs = final_inputs.to_numpy()\n",
    "        \n",
    "        print(self.color.BOLD+'\\nBest Performing Model Prediction'+self.color.END)\n",
    "        print(self.best_model[0]+ ' predicts --> ' + self.color.BLUE + str(self.best_model[1]['Model'].predict(final_inputs)[0]) + self.color.END)\n",
    "        \n",
    "        print(self.color.BOLD+'\\nAll Model Predictions'+self.color.END)\n",
    "        all_preds = []\n",
    "        for k, v in self.model_comparison.items():\n",
    "            print(str(k)+ ' predicts -->', self.color.BLUE + str(v['Model'].predict(final_inputs)[0]) + self.color.END)    \n",
    "            all_preds.append(v['Model'].predict(inputs)[0])\n",
    "        \n",
    "        try:\n",
    "            print(self.color.BOLD+'\\nMost Common Prediction '+self.color.END + '--> '+ self.color.BLUE+ str(mode(all_preds)) + self.color.END)\n",
    "        except StatisticsError:\n",
    "            print (self.color.BOLD+'\\nNo unique mode found.'+self.color.END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
